{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Lab Activity: Predicting Nationality from Names using Machine Learning**\n",
        "\n",
        "#### **1. Data**\n",
        "\n",
        "For this lab activity, we will use a dataset containing names from various nationalities. The dataset is organized into different text files, each corresponding to a specific nationality. For example, you might have files named `English.txt`, `French.txt`, etc. Each file contains a list of names from that nationality.\n",
        "\n",
        "#### **2. Representation**\n",
        "\n",
        "To train our machine learning model, we need to convert the names into a numerical format. Here are the key steps for data representation:\n",
        "- **Character-to-Index Conversion**: Each character in a name is mapped to an index based on a predefined vocabulary.\n",
        "- **Padding**: Names are padded to a consistent length to ensure they have the same dimensions.\n",
        "- **Character Embeddings**: The character indices are transformed into dense vectors using an embedding layer. This helps capture more nuanced information about the characters.\n",
        "\n",
        "#### **3. Prediction Model**\n",
        "\n",
        "We will use a Multi-Layer Perceptron (MLP) for predicting the nationality of a given name. Hereâ€™s a brief overview of the model architecture:\n",
        "- **Embedding Layer**: Transforms character indices into dense vectors.\n",
        "- **Fully Connected Layer**: Flattens the embeddings and passes them through a linear layer to generate predictions.\n",
        "- **Output Layer**: Produces probability scores for each nationality.\n",
        "\n",
        "The model is trained using cross-entropy loss and optimized with the Adam optimizer. After training, the model can predict the nationality of new names based on the learned patterns.\n"
      ],
      "metadata": {
        "id": "L6JxDYY60gfG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fHJ_8tEoBZcg"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import unicodedata\n",
        "import string\n",
        "import requests\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv__pJonFThO"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5K2blrO9FXzd"
      },
      "outputs": [],
      "source": [
        "all_letters = string.ascii_letters + \" .,;'-<PAD><UNK>\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def letterToIndex(letter):\n",
        "    index = all_letters.find(letter)\n",
        "    if index == -1:  # Handle unknown characters\n",
        "        index = all_letters.find('<UNK>')  # Use index for unknown characters\n",
        "    return index\n",
        "\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), 1, n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Define the GitHub repository URL and branch\n",
        "github_url = 'https://api.github.com/repos/DrUzair/NLP/contents/data/names'\n",
        "branch = 'f8e0c40481b1c1e32440b1da39c8bdfc9f070ffa'\n",
        "\n",
        "# Initialize dictionaries to store data\n",
        "all_categories = []\n",
        "category_lines = {}\n",
        "\n",
        "# Make a request to the GitHub API to get the list of files in the directory\n",
        "response = requests.get(f'{github_url}?ref={branch}')\n",
        "\n",
        "if response.status_code == 200:\n",
        "    file_data = response.json()\n",
        "\n",
        "    for file_info in file_data:\n",
        "        if file_info['type'] == 'file' and file_info['name'].endswith('.txt'):\n",
        "            file_url = file_info['download_url']\n",
        "            category = file_info['name'].split('.')[0]\n",
        "\n",
        "            # Add the category to the list\n",
        "            all_categories.append(category)\n",
        "\n",
        "            # Make a request to download the file\n",
        "            file_response = requests.get(file_url)\n",
        "\n",
        "            if file_response.status_code == 200:\n",
        "                # Read and store the file content\n",
        "                lines = file_response.text.split('\\n')\n",
        "                category_lines[category] = lines\n",
        "            else:\n",
        "                print(f\"Failed to download file: {file_info['name']}\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve file list from GitHub: {response.status_code}\")\n",
        "\n",
        "n_categories = len(all_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7R8Sx94HfwY",
        "outputId": "829c62dd-2dcf-464c-bad0-1e973b175e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
            "18\n"
          ]
        }
      ],
      "source": [
        "print(all_categories)\n",
        "print(len(all_categories))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NameDataset"
      ],
      "metadata": {
        "id": "gYVTRgRM00J7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the Dataset class to handle unknown characters\n",
        "class NameDataset(Dataset):\n",
        "    def __init__(self, category_lines, all_categories):\n",
        "        self.category_lines = category_lines\n",
        "        self.all_categories = all_categories\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.max_len = max([len(line) for lines in category_lines.values() for line in lines])\n",
        "        self.prepare_data()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        for category in self.all_categories:\n",
        "            for line in self.category_lines[category]:\n",
        "                self.data.append(line)\n",
        "                self.labels.append(self.all_categories.index(category))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        name_idx = [letterToIndex(char) for char in name]\n",
        "        name_idx = name_idx + [letterToIndex('<PAD>')] * (self.max_len - len(name_idx))\n",
        "        return torch.tensor(name_idx), torch.tensor(label)\n"
      ],
      "metadata": {
        "id": "ZoyxOmRlRgw-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the DataLoader\n",
        "def inspect_dataloader(dataloader):\n",
        "    for i, (names, labels) in enumerate(dataloader):\n",
        "        print(f\"Batch {i+1}\")\n",
        "        print(\"Names (indices):\", names)\n",
        "        print(\"Labels:\", labels)\n",
        "        if i >= 0:  # Inspect the first 3 batches only\n",
        "            break"
      ],
      "metadata": {
        "id": "mmaQVWtWwEEC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the DataLoader\n",
        "dataset = NameDataset(category_lines, all_categories)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "def inspect_dataloader(dataloader):\n",
        "    for i, (names, labels) in enumerate(dataloader):\n",
        "        print(f\"Batch {i+1}\")\n",
        "        print(\"Names (indices):\", names)\n",
        "        print(\"Labels:\", labels)\n",
        "        print(\"Names Shape:\", names.shape)  # Print shape of names tensor\n",
        "        # Check if any index is out of range\n",
        "        if torch.any(names >= n_letters) or torch.any(names < 0):\n",
        "            print(\"Error: Found indices out of range\")\n",
        "            print(names)\n",
        "            break\n",
        "        if i >= 2:  # Inspect the first 3 batches only\n",
        "            break\n",
        "\n",
        "inspect_dataloader(dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VHfoDL9uSyp_",
        "outputId": "d959445d-8897-480a-c3a5-f1459b948c9e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1\n",
            "Names (indices): tensor([[27,  8, 17, 12,  0, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 17,  8,  6, 14, 17, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38,  2, 19,  0,  6,  6,  0, 17, 19, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [26,  6, 17,  0, 13, 14,  5,  5, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [35, 20, 10, 14, 21,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 14, 19,  0,  7, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29, 17,  8,  5,  5,  8,  4, 11,  3, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44,  4,  6, 17,  4, 19,  8, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [37, 14, 17,  4, 13, 19, 25, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 17, 14, 18, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38,  8,  2,  7,  4, 11, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29,  0, 13, 56, 36, 14, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [30,  0, 17, 11,  4, 24, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 18,  4,  8, 19, 11,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [27,  0, 11,  0,  7, 14, 13, 18, 10, 24, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [36,  0, 20,  5, 12,  0, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [33,  0, 21, 10,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [43, 14,  6,  0, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [28,  0, 18, 18,  8,  3, 24, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 20, 17, 20,  7,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [36,  4,  8, 11, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [41, 14, 10,  7,  8, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38, 14, 17,  4, 19, 19,  8, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 14, 20,  6,  7, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 11,  0, 25,  0, 19, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44, 20,  4, 17, 14, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [35,  0, 19, 18, 10, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32,  0,  6, 11,  8,  0, 17,  3,  8, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [41,  0, 20, 11,  8, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32,  0, 18,  8, 13, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [26, 18,  7, 19, 14, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38,  2, 13,  4,  8, 11, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58]])\n",
            "Labels: tensor([14, 14,  4, 14, 14,  0,  4,  9,  6,  6,  4, 14,  4, 14, 14,  4, 14,  4,\n",
            "         8, 14,  6, 14,  9,  4, 14, 16, 14,  9,  6, 14,  4,  8])\n",
            "Names Shape: torch.Size([32, 20])\n",
            "Batch 2\n",
            "Names (indices): tensor([[41,  7,  4, 11, 15, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29,  0,  7,  4, 17, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [37, 14, 13,  6, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [27,  0,  8, 19, 14,  5,  5, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [33, 11, 20, 19, 10, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38, 14,  6,  7,  0,  3,  0, 12, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47,  0, 11, 19,  2,  7, 20, 10, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47,  0,  3,  1, 14, 11, 18, 10, 24, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [27,  0,  8,  6, 20, 25, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [39,  4, 22,  4, 11, 11, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44,  7,  0, 12, 12,  0, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 25,  4, 11, 20,  8, 10, 14, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38, 14, 17,  2, 14, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32,  0, 13,  8, 12, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 14, 17,  1, 20, 25,  4, 13, 10, 14, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [41, 24, 17,  2,  7,  4, 13, 10, 14, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [28, 14, 17, 12,  0,  2, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44,  7,  0, 12, 12,  0, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 20, 12,  0, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44,  7,  8, 13, 14, 25,  0, 10,  8, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 14, 21, 14, 17, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [31, 20,  4, 13, 19,  4, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [43,  4,  8,  3, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [51,  4, 11, 11, 22,  4,  6,  4, 17, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [33,  0, 11,  4,  4, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [26, 18, 19, 11,  4, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32,  0, 13,  8, 12, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47, 14, 25, 13,  8, 19, 18,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [35,  0,  1, 11, 14,  2,  7, 10,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38,  0, 17, 14, 20, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [33,  0, 11, 20, 19,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47,  0, 18, 24, 20, 19,  8, 13, 18, 10, 24, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58]])\n",
            "Labels: tensor([ 4,  0,  1, 14, 14,  0, 14, 14, 14,  4,  0, 14,  0,  0, 14, 14,  8,  0,\n",
            "         0, 10, 14, 16,  4,  6, 14,  4,  0, 14, 14,  0, 14, 14])\n",
            "Names Shape: torch.Size([32, 20])\n",
            "Batch 3\n",
            "Names (indices): tensor([[37, 20, 12, 11,  4, 24, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 14, 12,  0, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47,  0, 11,  3,  0,  4, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [31, 11,  4,  4, 19, 22, 14, 14,  3, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [27, 20, 17,  6, 18, 19,  0, 11, 11,  4, 17, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29,  8, 52, 18, 19,  4,  5,  0, 13, 14, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [37,  4, 21,  8, 19, 19, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47,  8,  2, 10,  0, 17, 18, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [27,  0, 25, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29, 17,  4, 22, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44,  4, 10,  8, 13,  4, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [31, 14, 19,  8,  4, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [26, 19, 19,  4, 17, 19, 14, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [32, 17, 14,  7,  0, 17, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 14, 19,  0,  7, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45, 14, 12,  0, 18,  4, 10, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [35,  0, 19, 18, 24, 10, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [36,  4, 13, 19, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45,  8,  7, 14,  3,  4,  4, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29,  0,  7, 11, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38,  0,  0, 11, 14, 20,  5, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [48, 17, 20,  2, 10, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [45,  8, 12,  0, 10, 14, 21, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [28,  7,  4, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [38, 20, 25,  6,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [29,  8, 19, 19, 12,  0, 17, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [47,  0, 13,  0,  6, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [36,  0,  8, 18,  4, 17, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [28,  7, 20,  7, 13,  8, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [37,  8, 21,  4, 13, 25, 14, 13, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [33, 14, 17,  8,  6, 14, 18,  7,  8, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58],\n",
            "        [44, 19,  4, 20,  1,  4, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
            "         58, 58]])\n",
            "Labels: tensor([ 4, 14, 14,  4,  6,  9, 14,  4,  0,  4, 10, 14,  4, 14,  0,  2, 14,  4,\n",
            "        14,  6,  0,  6, 14,  1, 14,  6, 14,  2, 14, 14, 10,  6])\n",
            "Names Shape: torch.Size([32, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "-eW83e-e07gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NameClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, max_len):\n",
        "        super(NameClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim * max_len, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "QpLQCKBMR2Mb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for names, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(names)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n"
      ],
      "metadata": {
        "id": "SiXmHGSYSKYR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NameDataset(category_lines, all_categories)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "max_len = dataset.max_len  # Define max_len based on the dataset\n",
        "vocab_size = len(all_letters)\n",
        "embed_dim = 16\n",
        "num_classes = n_categories\n",
        "max_len = dataset.max_len\n",
        "\n",
        "model = NameClassifier(vocab_size, embed_dim, num_classes, max_len)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 20\n",
        "\n",
        "train_model(model, dataloader, criterion, optimizer, num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MEL_7W43SEQC",
        "outputId": "887d77dc-980d-4332-b6c9-c604782a6b37"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.424667982633706\n",
            "Epoch 2, Loss: 1.1186335546195887\n",
            "Epoch 3, Loss: 1.017360669270063\n",
            "Epoch 4, Loss: 0.9556197317637456\n",
            "Epoch 5, Loss: 0.9128345596562525\n",
            "Epoch 6, Loss: 0.8837758338280545\n",
            "Epoch 7, Loss: 0.8586434003938536\n",
            "Epoch 8, Loss: 0.8405353678924263\n",
            "Epoch 9, Loss: 0.8273091610687174\n",
            "Epoch 10, Loss: 0.8143955353813567\n",
            "Epoch 11, Loss: 0.8036792738612291\n",
            "Epoch 12, Loss: 0.7961930720621992\n",
            "Epoch 13, Loss: 0.7893191932872602\n",
            "Epoch 14, Loss: 0.782509991080518\n",
            "Epoch 15, Loss: 0.7789353146010144\n",
            "Epoch 16, Loss: 0.775368066967293\n",
            "Epoch 17, Loss: 0.7708929920462286\n",
            "Epoch 18, Loss: 0.765097949630136\n",
            "Epoch 19, Loss: 0.7606734704155071\n",
            "Epoch 20, Loss: 0.7583556070354334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "oz3bkBpz1J0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for names, labels in dataloader:\n",
        "            outputs = model(names)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct / total\n",
        "    print(f'Evaluation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Example usage:\n",
        "dataset = NameDataset(category_lines, all_categories)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "evaluate_model(model, dataloader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I60EJIJly-Jc",
        "outputId": "c925cdc1-fc0e-4736-fe9d-b058c5ec9e82"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Loss: 0.7389, Accuracy: 0.7610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7389168261437659, 0.7609994027473621)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "malJZFzjf8Ik"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gt2mCSrZf9sV",
        "outputId": "75d486e6-f3be-4e29-e827-0793334d87bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3.15) Arabic\n",
            "(2.06) English\n",
            "(1.82) Russian\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Assuming 'model' is your trained model and 'all_categories' is your list of categories\n",
        "def evaluate(line_tensor):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        output = model(line_tensor)\n",
        "    return output\n",
        "\n",
        "def predict(name, n_predictions=3):\n",
        "    # Convert the name to a tensor of indices\n",
        "    name_idx = [letterToIndex(char) for char in name]\n",
        "    name_idx = name_idx + [letterToIndex('<PAD>')] * (max_len - len(name_idx))  # Pad the name if necessary\n",
        "    name_tensor = torch.tensor(name_idx).unsqueeze(0)  # Add batch dimension\n",
        "    name_tensor = name_tensor.long()  # Ensure the tensor is of type LongTensor\n",
        "\n",
        "    # Evaluate the model\n",
        "    output = evaluate(Variable(name_tensor))\n",
        "\n",
        "    # Get top N categories\n",
        "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(n_predictions):\n",
        "        value = topv[0][i].item()  # Convert tensor to scalar\n",
        "        category_index = topi[0][i].item()  # Convert tensor to scalar\n",
        "        predictions.append((value, all_categories[category_index]))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "name = 'ahmad'\n",
        "predictions = predict(name)\n",
        "for value, category in predictions:\n",
        "    print(f'({value:.2f}) {category}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}