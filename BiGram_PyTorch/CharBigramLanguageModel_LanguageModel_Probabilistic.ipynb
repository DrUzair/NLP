{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-LG4o1l_8EY",
        "outputId": "929940f6-7c44-4aac-fbc1-89fa95b78b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.util import bigrams\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "class CharBigramLanguageModel:\n",
        "    def __init__(self, lambda_smoothing=0.1):\n",
        "        self.unigram_counts = Counter()\n",
        "        self.bigram_counts = Counter()\n",
        "        self.vocab_size = 0\n",
        "        self.lambda_smoothing = lambda_smoothing\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Cleans text and converts it into a list of characters.\"\"\"\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Normalize spaces\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
        "        text = text.lower()  # Convert to lowercase\n",
        "        return list(text)  # Return as a list of characters\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"Trains the model by computing unigram and bigram counts.\"\"\"\n",
        "        chars = self.preprocess_text(text)\n",
        "        self.vocab_size = len(set(chars))  # Vocabulary size (unique characters)\n",
        "        self.unigram_counts.update(chars)\n",
        "        self.bigram_counts.update(bigrams(chars))\n",
        "\n",
        "    def compute_bigram_probability(self, char1, char2):\n",
        "        \"\"\"Computes bigram probability using Lidstone smoothing.\"\"\"\n",
        "        bigram_count = self.bigram_counts[(char1, char2)]\n",
        "        unigram_count = self.unigram_counts[char1]\n",
        "\n",
        "        probability = (bigram_count + self.lambda_smoothing) / (unigram_count + self.lambda_smoothing * self.vocab_size)\n",
        "        return probability\n",
        "\n",
        "    def generate_sequence(self, start_char, length=20):\n",
        "      \"\"\"Generates a character sequence starting from a given character, with randomness.\"\"\"\n",
        "      sequence = [start_char]\n",
        "      for _ in range(length - 1):\n",
        "          possible_chars = [char for char in self.unigram_counts.keys() if (sequence[-1], char) in self.bigram_counts]\n",
        "          if not possible_chars:\n",
        "              break  # Stop if no valid next character\n",
        "          # Compute probabilities for the next character\n",
        "          probabilities = [self.compute_bigram_probability(sequence[-1], char) for char in possible_chars]\n",
        "          # Normalize probabilities to sum to 1\n",
        "          total_prob = sum(probabilities)\n",
        "          normalized_probs = [p / total_prob for p in probabilities]\n",
        "\n",
        "          # Choose the next character randomly based on the probability distribution\n",
        "          next_char = random.choices(possible_chars,\n",
        "                                     weights=normalized_probs,\n",
        "                                     k=1)[0]\n",
        "          sequence.append(next_char)\n",
        "      return ''.join(sequence)\n",
        "\n",
        "def fetch_text_from_url(url):\n",
        "    \"\"\"Fetches raw text from a given URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return response.text\n",
        "\n",
        "# Example usage\n",
        "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"  # Example: Pride and Prejudice\n",
        "text = fetch_text_from_url(url)\n",
        "text = \"\"\"a quick brown fox jumps over the lazy dog.\n",
        "          lazy dog and a quick brown fox.\n",
        "          the dog is lazy and the fox jumps quickly.\n",
        "          a fox jumps over the dog because he is lazy.\n",
        "          dog is lazy and fox is brown. she quickly jumps over the lazy dog.\n",
        "          the brown fox watches the lazy dog before jumping.\n",
        "          a lazy dog sleeps under the tree while the fox waits.\n",
        "          the quick fox sees the dog resting and leaps past him.\n",
        "          a small fox chases the dog, but he is too slow.\n",
        "          the dog barks at the fox, but she is already gone.\n",
        "          over the fence, the fox jumps while the dog sighs.\n",
        "          a sleepy dog ignores the fox playing nearby.\n",
        "          the fox teases the lazy dog, who refuses to move.\n",
        "          under the bright moon, the fox runs and the dog yawns.\n",
        "          the brown fox leaps higher than the sleepy dog can see.\n",
        "          beside the river, the lazy dog naps as the fox splashes.\n",
        "          a clever fox waits until the dog closes his eyes before running.\n",
        "          the dog stretches and yawns while the fox rushes past.\n",
        "          the fox circles the dog, but he remains still and calm.\n",
        "          a quick fox dashes through the grass, leaving the lazy dog behind.\n",
        "          \"\"\"\n",
        "# Train the model\n",
        "char_bigram_model = CharBigramLanguageModel(lambda_smoothing=0.1)\n",
        "char_bigram_model.train(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query probability\n",
        "char1, char2 = \"a\", \"t\"\n",
        "prob = char_bigram_model.compute_bigram_probability(char1, char2)\n",
        "print(f\"P('{char2}' | '{char1}') = {prob:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw1cmX3jBcGJ",
        "outputId": "74b10bec-d785-4eda-8152-600faf0817e9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P('t' | 'a') = 0.0364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a sequence\n",
        "generated_sequence = char_bigram_model.generate_sequence(\"a\", length=50)\n",
        "print(\"Generated Sequence:\", generated_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKKkKZvbBVq_",
        "outputId": "691733fd-0f5e-44e8-d808-6d271b61f128"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sequence: and th s de r fe the deathr azy thives thetica ay \n"
          ]
        }
      ]
    }
  ]
}