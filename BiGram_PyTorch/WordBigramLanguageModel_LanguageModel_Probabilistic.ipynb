{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gya4fK68-rf",
        "outputId": "7c936a9f-a75c-4570-85d6-8f2f1be9c057"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYXFFGoK8Xck",
        "outputId": "c7184e1e-e93d-468f-9629-ca8b7c00c360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.util import bigrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "class BigramLanguageModel:\n",
        "    def __init__(self, lambda_smoothing=0.1):\n",
        "        self.unigram_counts = Counter()\n",
        "        self.bigram_counts = Counter()\n",
        "        self.vocab_size = 0\n",
        "        self.lambda_smoothing = lambda_smoothing\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Cleans and tokenizes text.\"\"\"\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Normalize spaces\n",
        "        #text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
        "        tokens = word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
        "        return tokens\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"Trains the model by computing unigram and bigram counts.\"\"\"\n",
        "        tokens = self.preprocess_text(text)\n",
        "        self.vocab_size = len(set(tokens))  # Vocabulary size\n",
        "        self.unigram_counts.update(tokens)\n",
        "        self.bigram_counts.update(bigrams(tokens))\n",
        "\n",
        "    def compute_bigram_probability(self, word1, word2):\n",
        "        \"\"\"Computes bigram probability using Lidstone smoothing.\"\"\"\n",
        "        bigram_count = self.bigram_counts[(word1, word2)]\n",
        "        unigram_count = self.unigram_counts[word1]\n",
        "\n",
        "        probability = (bigram_count + self.lambda_smoothing) / (unigram_count + self.lambda_smoothing * self.vocab_size)\n",
        "        return probability\n",
        "\n",
        "    def generate_sequence(self, start_word, length=20):\n",
        "      \"\"\"Generates a sequence of words starting from a given word, with randomness.\"\"\"\n",
        "      sequence = [start_word]\n",
        "      for _ in range(length - 1):\n",
        "          # Get possible next words\n",
        "          possible_words = [word for word in self.unigram_counts.keys() if (sequence[-1], word) in self.bigram_counts]\n",
        "          if not possible_words:\n",
        "            # Backoff to unigram probabilities\n",
        "            possible_words = list(self.unigram_counts.keys())\n",
        "            if not possible_words:\n",
        "              break  # Stop if no valid next word\n",
        "            total_unigram_count = sum(self.unigram_counts.values())  # Sum of all word counts\n",
        "            denominator = total_unigram_count + (self.lambda_smoothing * len(self.unigram_counts))  # Apply Lidstone smoothing to the denominator\n",
        "            probabilities = [(self.unigram_counts[word] + self.lambda_smoothing) / denominator for word in possible_words]\n",
        "          else:\n",
        "            # Use bigram probabilities\n",
        "            probabilities = [self.compute_bigram_probability(sequence[-1], word) for word in possible_words]\n",
        "          # Compute probabilities for the next word using Lidstone smoothing\n",
        "          probabilities = [self.compute_bigram_probability(sequence[-1], word) for word in possible_words]\n",
        "          # Normalize probabilities to sum to 1\n",
        "          total_prob = sum(probabilities)\n",
        "          normalized_probs = [p / total_prob for p in probabilities]\n",
        "          # Choose the next word randomly based on the probability distribution\n",
        "          next_word = random.choices(possible_words, weights=normalized_probs, k=1)[0]\n",
        "          sequence.append(next_word)\n",
        "\n",
        "      return ' '.join(sequence)\n",
        "\n",
        "def fetch_text_from_url(url):\n",
        "    \"\"\"Fetches raw text from a given URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return response.text\n",
        "\n",
        "# Example usage\n",
        "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"  # Example: Pride and Prejudice\n",
        "text = fetch_text_from_url(url)\n",
        "text = \"\"\"a quick brown fox jumps over the lazy dog.\n",
        "          lazy dog and a quick brown fox.\n",
        "          the dog is lazy and the fox jumps quickly.\n",
        "          a fox jumps over the dog because he is lazy.\n",
        "          dog is lazy and fox is brown. she quickly jumps over the lazy dog.\n",
        "          the brown fox watches the lazy dog before jumping.\n",
        "          a lazy dog sleeps under the tree while the fox waits.\n",
        "          the quick fox sees the dog resting and leaps past him.\n",
        "          a small fox chases the dog, but he is too slow.\n",
        "          the dog barks at the fox, but she is already gone.\n",
        "          over the fence, the fox jumps while the dog sighs.\n",
        "          a sleepy dog ignores the fox playing nearby.\n",
        "          the fox teases the lazy dog, who refuses to move.\n",
        "          under the bright moon, the fox runs and the dog yawns.\n",
        "          the brown fox leaps higher than the sleepy dog can see.\n",
        "          beside the river, the lazy dog naps as the fox splashes.\n",
        "          a clever fox waits until the dog closes his eyes before running.\n",
        "          the dog stretches and yawns while the fox rushes past.\n",
        "          the fox circles the dog, but he remains still and calm.\n",
        "          a quick fox dashes through the grass, leaving the lazy dog behind.\n",
        "          \"\"\"\n",
        "# Train the model\n",
        "bigram_model = BigramLanguageModel(lambda_smoothing=0.1)\n",
        "bigram_model.train(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query probability\n",
        "word1, word2 = \"dog\", \"is\"\n",
        "prob = bigram_model.compute_bigram_probability(word1, word2)\n",
        "print(f\"P({word2} | {word1}) = {prob:.8f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRJfn0dT9QGa",
        "outputId": "cf45fb12-4715-45f8-a86b-1c31b4acfbda"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(is | dog) = 0.07241379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sentence\n",
        "generated_sentence = bigram_model.generate_sequence(\"brown\", length=100)\n",
        "print(\"Generated Sentence:\", generated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTQG11_S9K-G",
        "outputId": "b3664b41-dc8e-4ce1-e441-587bc8aa871c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: brown fox jumps while the fox jumps over the lazy dog , the brown fox watches the brown fox jumps while the bright moon , who refuses to move . the river , the fox sees the lazy dog stretches and fox jumps quickly jumps over the fox jumps over the fox circles the fox splashes . beside the dog behind . the dog . the fox waits until the lazy dog . beside the bright moon , but she quickly . the dog resting and the fox leaps past him . a quick brown fox jumps while the fox\n"
          ]
        }
      ]
    }
  ]
}